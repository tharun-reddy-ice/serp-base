# ğŸŒŸ burp.ai - AI-Powered Data Extraction Platform

<div align="center">
  <img src="https://img.shields.io/badge/React-18.2.0-blue?style=for-the-badge&logo=react" alt="React" />
  <img src="https://img.shields.io/badge/Flask-2.3.0-green?style=for-the-badge&logo=flask" alt="Flask" />
  <img src="https://img.shields.io/badge/Python-3.9+-yellow?style=for-the-badge&logo=python" alt="Python" />
  <img src="https://img.shields.io/badge/License-MIT-red?style=for-the-badge" alt="License" />
</div>

## ğŸ“– Overview

**burp.ai** is an advanced AI-powered data extraction platform that enables intelligent web scraping across multiple e-commerce and content platforms. Built with a modern React frontend and robust Flask backend, it provides a beautiful glass morphism interface for seamless data extraction and analysis.

## âœ¨ Key Features

### ğŸ¯ **Core Functionality**
- **Multi-Platform Support** - Amazon, Flipkart, Snapdeal, Wikipedia scraping
- **AI-Enhanced Extraction** - Intelligent data processing and normalization
- **Real-time Scraping** - Live data extraction with progress tracking
- **Advanced Anti-Detection** - Smart scraping with built-in protection

### ğŸ“Š **Data Management**
- **Multiple Export Formats** - JSON, CSV, Excel, XML exports
- **Interactive Table View** - Sortable, searchable, paginated data display
- **Advanced Filtering** - Search and filter capabilities
- **Bulk Operations** - Select and export specific data rows

### ğŸ“ˆ **Analytics Dashboard**
- **Usage Statistics** - Comprehensive API call tracking
- **Visual Charts** - Pie charts, bar charts, usage trends
- **Performance Metrics** - Success rates, error tracking
- **Export Analytics** - Download usage reports

### ğŸ¨ **User Interface**
- **Glass Morphism Design** - Beautiful, modern interface
- **Multi-Theme Support** - Black, white, and grey themes
- **Responsive Layout** - Works on desktop, tablet, and mobile
- **Progressive Web App** - Offline-capable functionality

### ğŸ” **Authentication & Security**
- **User Authentication** - Secure login system
- **Profile Management** - User settings and preferences
- **Session Persistence** - Remember user sessions

## ğŸš€ Quick Start

### Prerequisites
- **Node.js** 16.0+ and npm
- **Python** 3.9+ and pip
- **Git** for version control

### Installation

#### Option 1: Quick Start (Recommended)
```bash
git clone https://github.com/tharun-reddy-ice/serp-base.git
cd serp-base
./start_all.sh
```

#### Option 2: Manual Setup
```bash
# 1. Clone Repository
git clone https://github.com/tharun-reddy-ice/serp-base.git
cd serp-base

# 2. Backend Setup
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# 3. Frontend Setup
cd ../frontend
npm install

# 4. Start Backend (Terminal 1)
cd ../backend
./start_backend.sh

# 5. Start Frontend (Terminal 2)
cd ../frontend
./start_frontend.sh
```

#### 6. Access the Application
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:5001

### Default Login Credentials
- **Username:** `tharun`
- **Password:** `demo123`

## ğŸ¯ How to Use

### Basic Scraping Workflow
1. **ğŸ” Login** to the platform using demo credentials
2. **ğŸ¯ Select Scraper** - Choose from Amazon, Flipkart, Snapdeal, or Wikipedia
3. **âš™ï¸ Configure Parameters** - Enter search terms and page limits
4. **ğŸš€ Start Scraping** - Click "Start Scraping" and watch real-time progress
5. **ğŸ“Š View Results** - Choose from JSON, Card, or Table view
6. **ğŸ’¾ Export Data** - Download in JSON, CSV, Excel, or XML format

### Advanced Features
- **ğŸ“‹ Table View**: Sort, filter, and select specific rows for export
- **ğŸ“ˆ Analytics**: Monitor your usage patterns and API performance
- **ğŸ¨ Themes**: Switch between beautiful black, white, and grey themes
- **ğŸ“¤ Bulk Export**: Export selected rows or complete datasets

## ğŸ“ Project Structure

```
serp-base/
â”œâ”€â”€ backend/                    # Flask Backend
â”‚   â”œâ”€â”€ app.py                 # Main Flask application
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ amazon_scraper.py      # Amazon scraping logic
â”‚   â”œâ”€â”€ flipkart_scraper.py    # Flipkart scraping logic
â”‚   â”œâ”€â”€ snapdeal.py           # Snapdeal scraping logic
â”‚   â””â”€â”€ wiki_json.py          # Wikipedia scraping logic
â”œâ”€â”€ frontend/                   # React Frontend
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html        # Main HTML template
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js            # Main React component
â”‚   â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ Analytics.js  # Analytics dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ Login.js      # Authentication system
â”‚   â”‚   â”‚   â”œâ”€â”€ TableView.js  # Advanced data table
â”‚   â”‚   â”‚   â”œâ”€â”€ Settings.js   # User preferences
â”‚   â”‚   â”‚   â”œâ”€â”€ ProfileDropdown.js # User profile
â”‚   â”‚   â”‚   â””â”€â”€ RequestsPage.js # Feature requests
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ exportUtils.js # Export functionality
â”‚   â”œâ”€â”€ package.json          # Node.js dependencies
â”‚   â””â”€â”€ package-lock.json
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”œâ”€â”€ start_all.sh              # Quick start script
â”œâ”€â”€ start_backend.sh          # Backend startup
â”œâ”€â”€ start_frontend.sh         # Frontend startup
â””â”€â”€ README.md                 # This documentation
```

## ğŸ› ï¸ Available Scripts

### Backend Scripts
```bash
python app.py              # Start Flask development server
./start_backend.sh         # Start backend with environment setup
python manual_test.py       # Run manual API tests
```

### Frontend Scripts
```bash
npm start                   # Start development server
npm build                   # Build for production
npm test                    # Run tests
./start_frontend.sh        # Start frontend with proper setup
```

### Combined Scripts
```bash
./start_all.sh             # Start both backend and frontend
```

## ğŸ“Š Supported Platforms

| Platform | Status | Data Types |
|----------|--------|------------|
| ğŸ›’ **Amazon** | âœ… Active | Products, prices, ratings, reviews, images |
| ğŸ›ï¸ **Flipkart** | âœ… Active | Products, prices, offers, specifications |
| ğŸª **Snapdeal** | âœ… Active | Products, discounts, seller information |
| ğŸ“š **Wikipedia** | âœ… Active | Articles, summaries, references, links |

## ğŸ”§ API Endpoints

### Core Endpoints
- `GET /api/scrapers` - Get available scrapers and configurations
- `POST /api/scrape` - Execute scraping with parameters
- `GET /api/health` - Health check and system status

### Example API Usage
```bash
# Get available scrapers
curl http://localhost:5001/api/scrapers

# Start scraping
curl -X POST http://localhost:5001/api/scrape \
  -H "Content-Type: application/json" \
  -d '{"scraper_id": "amazon", "parameters": {"search_term": "laptop", "max_pages": 2}}'
```

## ğŸ“ˆ Analytics Features

- **ğŸ“Š Real-time Dashboard**: Monitor API calls, success rates, and usage patterns
- **ğŸ“ˆ Visual Charts**: Interactive pie charts showing scraper usage distribution
- **ğŸ“‹ Usage Statistics**: Track daily, weekly, and monthly scraping activity
- **ğŸ’¾ Export Analytics**: Download detailed usage reports
- **ğŸ¯ Performance Insights**: Identify most/least used scrapers and peak usage times

## ğŸ¨ Theme System

burp.ai features a sophisticated theme system with three beautiful options:

- **ğŸ–¤ Black Theme**: Professional dark mode with high contrast
- **âšª White Theme**: Clean light mode for bright environments  
- **ğŸŒ«ï¸ Grey Theme**: Balanced neutral theme for extended usage

Themes apply globally and persist across sessions with localStorage integration.

## ğŸ’¾ Export Capabilities

### Supported Formats
- **ğŸ“„ JSON**: Complete data with metadata
- **ğŸ“Š CSV**: Spreadsheet-compatible format
- **ğŸ“ˆ Excel**: Native Excel format (.xlsx)
- **ğŸ—‚ï¸ XML**: Structured markup format

### Export Options
- **All Data**: Export complete dataset
- **Selected Rows**: Export only chosen table rows
- **Smart Naming**: Automatic filename generation with timestamps

## ğŸ”’ Security Features

- **Authentication System**: Secure login with session management
- **Input Validation**: Comprehensive parameter validation
- **Rate Limiting**: Built-in protection against abuse
- **Data Sanitization**: Clean and safe data processing
- **CORS Protection**: Proper cross-origin resource sharing

## ğŸ¤ Contributing

We welcome contributions! Please follow these guidelines:

1. **Fork** the repository on GitHub
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request with detailed description

### Development Guidelines
- Follow PEP 8 for Python code
- Use ESLint/Prettier for JavaScript formatting
- Write meaningful commit messages
- Add tests for new features
- Update documentation as needed

## ğŸ› Troubleshooting

### Common Issues

**Backend Issues:**
- **Port 5001 in use**: Kill existing processes or change port in app.py
- **Module not found**: Ensure virtual environment is activated
- **Permission denied**: Check file permissions for script files

**Frontend Issues:**
- **Port 3000 in use**: React will prompt to use different port
- **npm install fails**: Clear npm cache with `npm cache clean --force`
- **Build errors**: Check Node.js version compatibility

**Scraping Issues:**
- **Anti-bot detection**: Some sites have advanced protection
- **Timeout errors**: Increase timeout values in scraper configs
- **Rate limiting**: Add delays between requests

### Performance Optimization
- Use pagination for large datasets
- Enable caching for repeated requests
- Monitor memory usage during bulk operations

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **React Team** for the powerful frontend framework
- **Flask Team** for the lightweight Python web framework
- **BeautifulSoup** for robust HTML parsing capabilities
- **Bootstrap** for responsive UI components
- **Chart.js** for beautiful data visualizations

## ğŸ“ Support & Contact

- **Email**: tharun@burp.ai
- **GitHub Issues**: Create an issue for bug reports or feature requests
- **Documentation**: Check this README for comprehensive guides

---

<div align="center">
  <strong>ğŸš€ Built with â¤ï¸ by the burp.ai Team</strong><br>
  <em>Empowering intelligent data extraction since 2024</em>
</div>